{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neru/M5/lib/python3.9/site-packages/sklearn/utils/linear_assignment_.py:18: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
      "  warnings.warn(\n",
      "/home/neru/M5/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#import necessary modules\n",
    "from src.sort import Sort\n",
    "from dataset import *\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import pickle\n",
    "import time\n",
    "import sys\n",
    "import io\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import xml.etree.ElementTree as ET\n",
    "import motmetrics as mm\n",
    "import numpy as np\n",
    "  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate SORT and load necessary files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2141/2141 [03:38<00:00,  9.81it/s]\n"
     ]
    }
   ],
   "source": [
    "#create instance of SORT\n",
    "mot_kalman_tracker = Sort()\n",
    "#frames to predict/visualise\n",
    "frame_start = 0\n",
    "frame_end = 2141\n",
    "\n",
    "#load sequence\n",
    "file_path = \"../datasets/AICity_data/train/S03/c010/vdo.avi\"\n",
    "out = []\n",
    "total_time = 0\n",
    "dataset_dicts = get_dicts('all', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pkl_bboxes(input_pkl_path):\n",
    "  \"\"\"Load bounding box predictions from a pkl file containing the predicted bounding boxes.\n",
    "  input_pkl_path: Input path of the pkl file containing gt and predicted bboxes. They are formatted in a two position array [bboxes_pred, bboxes_gt].\n",
    "  This file can be generated saving bbox_pred and bbox_gt from task 1.1\n",
    "  Outputs:\n",
    "      pred_bboxes_proper_format: Predicted bboxes in the SORT format (List of lists where each box is defined as [xtl, ytl, xbr, ybr])\n",
    "  \n",
    "  \"\"\"\n",
    "  #load detections\n",
    "  with open(input_pkl_path, 'rb') as handle:\n",
    "      detections_dict = pickle.load(handle)\n",
    "\n",
    "\n",
    "  bboxes_pred = detections_dict[0]\n",
    "  bboxes_gt = detections_dict[1]\n",
    "  detections = []\n",
    "  index = frame_start\n",
    "  pred_bboxes_proper_format = []\n",
    "\n",
    "  for detection_index in bboxes_pred:\n",
    "      bboxes_pred_list = bboxes_pred[detection_index]\n",
    "      bboxes_gt_list = bboxes_gt[detection_index]\n",
    "      curr_bboxes = []\n",
    "      for bbox in bboxes_pred_list:\n",
    "          bbox_proper_format = [ bbox['xtl'],  bbox['ytl'],bbox['xbr'],  bbox['ybr']]\n",
    "          curr_bboxes.append(bbox_proper_format)\n",
    "      pred_bboxes_proper_format.append(curr_bboxes)\n",
    "      index +=1\n",
    "\n",
    "  return pred_bboxes_proper_format\n",
    "\n",
    "def read_csv_bboxes(input_txt_path):\n",
    "  \"\"\"Load bounding box predictions from a txt file containing the predicted bounding boxes.\n",
    "  input_txt_path: Input path of the pkl file containing the predicted bboxes. Each row is written in the MOT challenge format\n",
    "  This file can be generated with the outputs of 2.1 (tracking ids are ignored)\n",
    "  Outputs:\n",
    "      pred_bboxes_proper_format: Predicted bboxes in the SORT format (List of lists where each box is defined as [xtl, ytl, xbr, ybr])\n",
    "  \n",
    "  \"\"\"\n",
    "  #load detections\n",
    "  pred_bboxes_proper_format = []\n",
    "  with open(\"output_retinanet.txt\", 'r') as file:\n",
    "    csvreader = csv.reader(file)\n",
    "    prev_frame = 1\n",
    "    curr_bboxes = []\n",
    "    for row in csvreader:\n",
    "      curr_frame = row[0]\n",
    "      if curr_frame!=prev_frame:\n",
    "        pred_bboxes_proper_format.append(curr_bboxes)\n",
    "        curr_bboxes = []\n",
    "        prev_frame = curr_frame\n",
    "      bbox_proper_format_temp = [ float(row[2]),  float(row[3]),float(row[4])+float(row[2]),  float(row[5])+float(row[3])]\n",
    "      curr_bboxes.append(bbox_proper_format_temp)\n",
    "  return pred_bboxes_proper_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#examples on loading them\n",
    "input_pkl_path = \"faster05.pkl\"\n",
    "pred_bboxes_proper_format = read_pkl_bboxes(input_pkl_path)\n",
    "input_txt_path = \"output_faster-rcnn.txt\"\n",
    "pred_bboxes_proper_format = read_csv_bboxes(input_txt_path)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict and visualise results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "frame_end=10\n",
    "frame_start = 0\n",
    "output_gif_filename = 'retinanettest.gif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neru/M5/lib/python3.9/site-packages/sklearn/utils/linear_assignment_.py:124: FutureWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def fig2img(fig):\n",
    "    buf = io.BytesIO()\n",
    "    fig.savefig(buf)\n",
    "    buf.seek(0)\n",
    "    img = Image.open(buf)\n",
    "    return img\n",
    "\n",
    "\n",
    "bboxes_gt = {}\n",
    "bboxes_pred = {}\n",
    "video_frames_out =[]\n",
    "index = frame_start\n",
    "\n",
    "colours = np.random.rand(32,3) #used only for display\n",
    "for d in dataset_dicts[frame_start:frame_end]:\n",
    "    image_id = d[\"image_id\"]\n",
    "    if image_id<frame_start or image_id>frame_end:\n",
    "        index = index+1\n",
    "        print(\"Skipping frame \", image_id)\n",
    "        continue\n",
    "\n",
    "    curr_detection = np.asarray(pred_bboxes_proper_format[index])\n",
    "    curr_frame = cv2.imread(d[\"file_name\"])\n",
    "    curr_frame = cv2.cvtColor(curr_frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    trackers = mot_kalman_tracker.update(curr_detection)\n",
    "    cycle_time = time.time() - start_time\n",
    "    total_time += cycle_time\n",
    "    index = index+1\n",
    "    \n",
    "\n",
    "    out.append(trackers)\n",
    "    #save gif\n",
    "    fig, ax = plt.subplots(1, 1, dpi=150)\n",
    "\n",
    "    ax.set_title('Faster R-CNN detections')\n",
    "    ax.imshow(curr_frame)\n",
    "    ax.axis('off')\n",
    "    for j in range(np.shape(curr_detection)[0]):\n",
    "        color = colours[j]\n",
    "        coords = (curr_detection[j,0],curr_detection[j,1]), curr_detection[j,2], curr_detection[j,3]\n",
    "        ax.add_patch(patches.Rectangle((coords[0][0],coords[0][1]),coords[1]-coords[0][0],coords[2]-coords[0][1],fill=False,lw=3, ec = (1,1,1)))\n",
    "\n",
    "    for d in trackers:\n",
    "        d = d.astype(np.uint32)\n",
    "        row = [image_id+1, d[4], d[0], d[1], d[2], d[3], -1,-1,-1,-1]\n",
    "        ax.add_patch(patches.Rectangle((d[0],d[1]),d[2]-d[0],d[3]-d[1],fill=False,lw=3,ec=colours[d[4]%32,:]))\n",
    "        ax.text(((d[0]+d[2])/2), max(0,(d[1]-30)), \"ID: \"+str(d[4]), horizontalalignment='center', verticalalignment='center',fontsize=12, color='white') \n",
    "\n",
    "    frame_out = fig2img(fig)\n",
    "    video_frames_out.append(frame_out)\n",
    "    plt.close(fig)\n",
    "video_frames_out[0].save(output_gif_filename, save_all=True, append_images=video_frames_out[1:], duration=30, loop=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read gt\n",
    "def parse_xml(file_path):\n",
    "    \"\"\"\n",
    "    Parses an XML file and extracts bounding box information for each frame and track.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the XML file.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing two dictionaries, `tracks` and `frames`.\n",
    "            `tracks` contains information for each track, with the track IDs as keys and the box information\n",
    "            for each frame as values.\n",
    "            `frames` contains information for each frame, with the frame numbers as keys and a list of boxes as\n",
    "            values.\n",
    "    \"\"\"\n",
    "    # Parse the XML file\n",
    "    tree = ET.parse(file_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    frames = {}\n",
    "\n",
    "    # Iterate over the tracks and extract their bounding box information\n",
    "    for track in root.findall(\".//track[@label='car']\"):\n",
    "        track_id = track.get('id')\n",
    "        for box in track.findall(\".//box\"):\n",
    "            box_frame = int(box.get('frame'))\n",
    "            xtl, ytl, xbr, ybr = map(float, [box.get('xtl'), box.get('ytl'), box.get('xbr'), box.get('ybr')])\n",
    "            outside, occluded, keyframe = map(int, [box.get('outside'), box.get('occluded'), box.get('keyframe')])\n",
    "            parked = box.find(\".//attribute[@name='parked']\").text == 'true'\n",
    "\n",
    "            # Add the box to the list of boxes for this frame\n",
    "            if box_frame not in frames:\n",
    "                frames[box_frame] = []\n",
    "\n",
    "            frames[box_frame].append({\n",
    "                'xtl': xtl,\n",
    "                'ytl': ytl,\n",
    "                'xbr': xbr,\n",
    "                'ybr': ybr,\n",
    "                'track_id': track_id,\n",
    "                'occluded': occluded\n",
    "            })\n",
    "\n",
    "    return frames\n",
    "\n",
    "\n",
    "frames_gt =parse_xml('../datasets/ai_challenge_s03_c010-full_annotation.xml')\n",
    "frames_gt = dict(sorted(frames_gt.items(), key=lambda x: x[0]))\n",
    "# Open the output file for writing\n",
    "output_file = \"output_annotations.txt\"\n",
    "output_fp = open(output_file, \"w\")\n",
    "for frame in frames_gt:\n",
    "    for bbox in frames_gt[frame]:\n",
    "        x, y, z = -1, -1, -1  # No information about x, y, z\n",
    "        line = \"{},{},{},{},{},{},{},{},{},{}\\n\".format(\n",
    "            str(int(frame)+1),\n",
    "            bbox['track_id'],\n",
    "            bbox['xtl'],\n",
    "            bbox['ytl'],\n",
    "            bbox['xbr'] - bbox['xtl'],\n",
    "            bbox['ybr'] - bbox['ytl'],\n",
    "            1,\n",
    "            x,\n",
    "            y,\n",
    "            z\n",
    "        )\n",
    "\n",
    "        output_fp.write(line)\n",
    "\n",
    "#Release the output file\n",
    "output_fp.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple way to compute metrics quick (the folder to do it with TrackEval is \"data_kalman/\")\n",
    "#from https://github.com/cheind/py-motmetrics\n",
    "\n",
    "def motMetricsEnhancedCalculator(gtSource, tSource):\n",
    "  # load ground truth\n",
    "  gt = np.loadtxt(gtSource, delimiter=',')\n",
    "\n",
    "  # load tracking output\n",
    "  t = np.loadtxt(tSource, delimiter=',')\n",
    "\n",
    "  # Create an accumulator that will be updated during each frame\n",
    "  acc = mm.MOTAccumulator(auto_id=True)\n",
    "\n",
    "  # Max frame number maybe different for gt and t files\n",
    "  for frame in range(int(gt[:,0].max())):\n",
    "    frame += 1 # detection and frame numbers begin at 1\n",
    "\n",
    "    # select id, x, y, width, height for current frame\n",
    "    # required format for distance calculation is X, Y, Width, Height \\\n",
    "    # We already have this format\n",
    "    gt_dets = gt[gt[:,0]==frame,1:6] # select all detections in gt\n",
    "    t_dets = t[t[:,0]==frame,1:6] # select all detections in t\n",
    "\n",
    "    C = mm.distances.iou_matrix(gt_dets[:,1:], t_dets[:,1:], \\\n",
    "                                max_iou=0.5) # format: gt, t\n",
    "\n",
    "    # Call update once for per frame.\n",
    "    # format: gt object ids, t object ids, distance\n",
    "    acc.update(gt_dets[:,0].astype('int').tolist(), \\\n",
    "              t_dets[:,0].astype('int').tolist(), C)\n",
    "\n",
    "  mh = mm.metrics.create()\n",
    "\n",
    "  summary = mh.compute(acc, metrics=['num_frames', 'idf1', 'idp', 'idr', \\\n",
    "                                     'recall', 'precision', 'num_objects', \\\n",
    "                                     'mostly_tracked', 'partially_tracked', \\\n",
    "                                     'mostly_lost', 'num_false_positives', \\\n",
    "                                     'num_misses', 'num_switches', \\\n",
    "                                     'num_fragmentations', 'mota', 'motp' \\\n",
    "                                    ], \\\n",
    "                      name='acc')\n",
    "\n",
    "  strsummary = mm.io.render_summary(\n",
    "      summary,\n",
    "      #formatters={'mota' : '{:.2%}'.format},\n",
    "      namemap={'idf1': 'IDF1', 'idp': 'IDP', 'idr': 'IDR', 'recall': 'Rcll', \\\n",
    "               'precision': 'Prcn', 'num_objects': 'GT', \\\n",
    "               'mostly_tracked' : 'MT', 'partially_tracked': 'PT', \\\n",
    "               'mostly_lost' : 'ML', 'num_false_positives': 'FP', \\\n",
    "               'num_misses': 'FN', 'num_switches' : 'IDsw', \\\n",
    "               'num_fragmentations' : 'FM', 'mota': 'MOTA', 'motp' : 'MOTP',  \\\n",
    "              }\n",
    "  )\n",
    "  print(strsummary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     num_frames      IDF1      IDP       IDR      Rcll      Prcn     GT  MT  PT  ML    FP     FN  IDsw  FM      MOTA     MOTP\n",
      "acc        2141  0.460036  0.52739  0.407937  0.532694  0.688679  21594  14  29  13  5200  10091    49  83  0.289617  0.14509\n",
      "     num_frames      IDF1       IDP       IDR     Rcll      Prcn     GT  MT  PT  ML    FP    FN  IDsw  FM      MOTA      MOTP\n",
      "acc        2141  0.506023  0.585667  0.445448  0.54881  0.721566  21594  14  31  11  4573  9743    65  96  0.334028  0.165039\n",
      "     num_frames     IDF1      IDP       IDR      Rcll      Prcn     GT  MT  PT  ML  FP     FN  IDsw   FM      MOTA      MOTP\n",
      "acc        2141  0.48833  0.73637  0.365287  0.494119  0.996079  21594  10  24  22  42  10924    73  100  0.488793  0.144266\n",
      "     num_frames      IDF1       IDP       IDR      Rcll      Prcn     GT  MT  PT  ML   FP   FN  IDsw  FM      MOTA      MOTP\n",
      "acc        2141  0.795711  0.808352  0.783458  0.960406  0.990922  21594  43  13   0  190  855    40  52  0.949755  0.065504\n"
     ]
    }
   ],
   "source": [
    "#due to memory issues, these files have been generated using the .py file as they required too \n",
    "motMetricsEnhancedCalculator('gt.txt', \\\n",
    "                             './outputs/kalman_dets_fasterrcnn.txt')\n",
    "motMetricsEnhancedCalculator('gt.txt', \\\n",
    "                             \"./outputs/kalman_dets_maskrcnn.txt\")\n",
    "motMetricsEnhancedCalculator('gt.txt', \\\n",
    "                             './outputs/kalman_dets_retinanet.txt')\n",
    "motMetricsEnhancedCalculator('gt.txt', \\\n",
    "                             \"./outputs/kalman_dets_finetuned.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "M5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
