{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hicha\\miniconda3\\envs\\week2\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import motmetrics\n",
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "import motmetrics\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to compute IOU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iou(bboxA, bboxB):\n",
    "    # Code provided by teacher in M1 subject\n",
    "    # compute the intersection over union of two bboxes\n",
    "    \n",
    "    # Format of the bboxes is [xtl, ytl, xbr, ybr, ...], where tl and br\n",
    "    # indicate top-left and bottom-right corners of the bbox respectively.\n",
    "\n",
    "    # determine the coordinates of the intersection rectangle\n",
    "    xA = max(bboxA[0], bboxB[0])\n",
    "    \n",
    "    yA = max(bboxA[1], bboxB[1])\n",
    "    xB = min(bboxA[2], bboxB[2])\n",
    "    yB = min(bboxA[3], bboxB[3])\n",
    "    \n",
    "    # compute the area of intersection rectangle\n",
    "    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    " \n",
    "    # compute the area of both bboxes\n",
    "    bboxAArea = (bboxA[3] - bboxA[1] + 1) * (bboxA[2] - bboxA[0] + 1)\n",
    "    bboxBArea = (bboxB[3] - bboxB[1] + 1) * (bboxB[2] - bboxB[0] + 1)\n",
    "    \n",
    "    iou = interArea / float(bboxAArea + bboxBArea - interArea)\n",
    "    \n",
    "    # return the intersection over union value\n",
    "    return iou\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert annotations.xml to gt.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "def parse_xml(file_path):\n",
    "    \"\"\"\n",
    "    Parses an XML file and extracts bounding box information for each frame and track.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the XML file.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing two dictionaries, `tracks` and `frames`.\n",
    "            `tracks` contains information for each track, with the track IDs as keys and the box information\n",
    "            for each frame as values.\n",
    "            `frames` contains information for each frame, with the frame numbers as keys and a list of boxes as\n",
    "            values.\n",
    "    \"\"\"\n",
    "    # Parse the XML file\n",
    "    tree = ET.parse(file_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    frames = {}\n",
    "\n",
    "    # Iterate over the tracks and extract their bounding box information\n",
    "    for track in root.findall(\".//track[@label='car']\"):\n",
    "        track_id = track.get('id')\n",
    "        for box in track.findall(\".//box\"):\n",
    "            box_frame = int(box.get('frame'))\n",
    "            xtl, ytl, xbr, ybr = map(float, [box.get('xtl'), box.get('ytl'), box.get('xbr'), box.get('ybr')])\n",
    "            outside, occluded, keyframe = map(int, [box.get('outside'), box.get('occluded'), box.get('keyframe')])\n",
    "            parked = box.find(\".//attribute[@name='parked']\").text == 'true'\n",
    "\n",
    "            # Add the box to the list of boxes for this frame\n",
    "            if box_frame not in frames:\n",
    "                frames[box_frame] = []\n",
    "\n",
    "            frames[box_frame].append({\n",
    "                'xtl': xtl,\n",
    "                'ytl': ytl,\n",
    "                'xbr': xbr,\n",
    "                'ybr': ybr,\n",
    "                'track_id': track_id,\n",
    "                'occluded': occluded\n",
    "            })\n",
    "\n",
    "    return frames\n",
    "\n",
    "\n",
    "frames_gt = parse_xml('annotations.xml')\n",
    "frames_gt = dict(sorted(frames_gt.items(), key=lambda x: x[0]))\n",
    "# Open the output file for writing\n",
    "output_file = \"output_annotations.txt\"\n",
    "output_fp = open(output_file, \"w\")\n",
    "\n",
    "for frame in frames_gt:\n",
    "    for bbox in frames_gt[frame]:\n",
    "        x, y, z = -1, -1, -1  # No information about x, y, z\n",
    "        line = \"{},{},{},{},{},{},{},{},{},{}\\n\".format(\n",
    "            str(int(frame)+1),\n",
    "            bbox['track_id'],\n",
    "            bbox['xtl'],\n",
    "            bbox['ytl'],\n",
    "            bbox['xbr'] - bbox['xtl'],\n",
    "            bbox['ybr'] - bbox['ytl'],\n",
    "            1,\n",
    "            x,\n",
    "            y,\n",
    "            z\n",
    "        )\n",
    "\n",
    "        output_fp.write(line)\n",
    "\n",
    "#Release the output file\n",
    "output_fp.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute object tracking using Detectron2 (Mask R-CNN, Retinanet, Faster R-CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the video\n",
    "video = cv2.VideoCapture('vdo.avi')\n",
    "\n",
    "\n",
    "#Load configuration\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\"))\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model\n",
    "# Find a model from detectron2's model zoo. You can use the https://dl.fbaipublicfiles... url as well\n",
    "cfg.MODEL.WEIGHTS = 'model_final.pth'\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "\n",
    "# Initialize variables\n",
    "\n",
    "object_tracker = {}\n",
    "current_id = 0\n",
    "frame_num = 1\n",
    "\n",
    "#Initialize video array\n",
    "video_output = []\n",
    "# Open the output file for writing\n",
    "output_file = \"output_faster-rcnn-finetuned.txt\"\n",
    "output_fp = open(output_file, \"w\")\n",
    "while True:\n",
    "    # Read the current frame from the video\n",
    "    \n",
    "    ret, frame = video.read()\n",
    "\n",
    "    # Stop if there are no more frames\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Detect objects in the current frame using the pretrained model\n",
    "    outputs = predictor(frame) \n",
    "    current_objects = outputs['instances']\n",
    "\n",
    "    instances = outputs[\"instances\"].to(\"cpu\")\n",
    "    boxes = instances.pred_boxes.tensor.numpy()\n",
    "    print(\"Boxes\", boxes)\n",
    "    classes = instances.pred_classes.numpy()\n",
    "    print(\"Classes\", classes)\n",
    "    #print(classes)\n",
    "    scores = instances.scores.numpy()\n",
    "    num_boxes = boxes.shape[0]\n",
    "    # Initialize a new dictionary to store the detected objects in the current frame\n",
    "    new_object_tracker = {}\n",
    "\n",
    "    for i in range(num_boxes):\n",
    "        box = boxes[i]\n",
    "        score = scores[i]\n",
    "        class_object = classes[i]\n",
    "        # Filter out low-scoring objects\n",
    "        if score < 0.5:\n",
    "            continue\n",
    "\n",
    "        # if class_object != 2:\n",
    "        #     continue\n",
    "\n",
    "        # Assign a new ID to each new detected object\n",
    "        current_id += 1\n",
    "        # Try to match the detected object with a previously tracked object based on IoU\n",
    "        best_match_id = None\n",
    "        best_match_iou = 0\n",
    "        for object_id, object_box in object_tracker.items():\n",
    "            iou = compute_iou(box, object_box)\n",
    "            if iou > best_match_iou:\n",
    "                best_match_iou = iou\n",
    "                best_match_id = object_id\n",
    "        # If the best match has IoU > 0.4, assign the same ID to the detected object\n",
    "        if best_match_id is not None and best_match_iou > 0.4:\n",
    "            new_object_tracker[best_match_id] = box\n",
    "            del object_tracker[best_match_id]\n",
    "        else:\n",
    "            new_object_tracker[current_id] = box\n",
    "\n",
    "        \n",
    "    # Update the object tracker for the current frame\n",
    "    object_tracker = new_object_tracker\n",
    "    # Visualize the tracked objects in the current frame\n",
    "    tracked_boxes = []\n",
    "    tracked_ids = []\n",
    "    v = Visualizer(frame[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
    "    #out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    index_color = 0\n",
    "    for object_id, object_box in object_tracker.items():\n",
    "        tracked_boxes.append(object_box)\n",
    "        tracked_ids.append(object_id)\n",
    "        out = v.draw_text(f\"{object_id}\", (object_box[0], object_box[1]), font_size=8)\n",
    "        out = v.draw_box(object_box, )\n",
    "    \n",
    "    result = out.get_image()[:, :, ::-1]\n",
    "    video_output.append(Image.fromarray(result))\n",
    "    # Display the current frame with the tracked objects\n",
    "    cv2.imshow(\"Object tracking\", result)\n",
    "    if cv2.waitKey(50) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "    # Write the tracker output to the output file in the MOT16 format\n",
    "    \n",
    "    for track, bbox in object_tracker.items():\n",
    "    \n",
    "        x, y, z = -1, -1, -1  # No information about x, y, z\n",
    "        line = \"{},{},{},{},{},{},{},{},{},{}\\n\".format(\n",
    "            frame_num,\n",
    "            track,\n",
    "            bbox[0],\n",
    "            bbox[1],\n",
    "            bbox[2] - bbox[0],\n",
    "            bbox[3] - bbox[1],\n",
    "            1,\n",
    "            x,\n",
    "            y,\n",
    "            z\n",
    "        )\n",
    "        output_fp.write(line)\n",
    "\n",
    "    frame_num += 1\n",
    "\n",
    "# Release the video and the output file and close all windows\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n",
    "output_fp.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "# Set up the video parameters\n",
    "video_name = 'my_video.mp4'\n",
    "fps = 30\n",
    "\n",
    "# Get the shape of the first image to set the size of the video\n",
    "height, width, _ = cv2.cvtColor(np.array(video_output[0]), cv2.COLOR_RGB2BGR).shape\n",
    "size = (width, height)\n",
    "\n",
    "# Create the video writer object\n",
    "video_writer = cv2.VideoWriter(video_name, cv2.VideoWriter_fourcc(*'mp4v'), fps, size)\n",
    "\n",
    "# Write each frame to the video\n",
    "for image in video_output:\n",
    "    video_writer.write(cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR))\n",
    "\n",
    "# Release the video writer\n",
    "video_writer.release()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using py-motmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def motMetricsEnhancedCalculator(gtSource, tSource):\n",
    "  # import required packages\n",
    "  import motmetrics as mm\n",
    "  import numpy as np\n",
    "  \n",
    "  # load ground truth\n",
    "  gt = np.loadtxt(gtSource, delimiter=',')\n",
    "\n",
    "  # load tracking output\n",
    "  t = np.loadtxt(tSource, delimiter=',')\n",
    "\n",
    "  # Create an accumulator that will be updated during each frame\n",
    "  acc = mm.MOTAccumulator(auto_id=True)\n",
    "\n",
    "  # Max frame number maybe different for gt and t files\n",
    "  for frame in range(int(gt[:,0].max())):\n",
    "    frame += 1 # detection and frame numbers begin at 1\n",
    "\n",
    "    # select id, x, y, width, height for current frame\n",
    "    # required format for distance calculation is X, Y, Width, Height \\\n",
    "    # We already have this format\n",
    "    gt_dets = gt[gt[:,0]==frame,1:6] # select all detections in gt\n",
    "    t_dets = t[t[:,0]==frame,1:6] # select all detections in t\n",
    "\n",
    "    C = mm.distances.iou_matrix(gt_dets[:,1:], t_dets[:,1:], \\\n",
    "                                max_iou=0.5) # format: gt, t\n",
    "\n",
    "    # Call update once for per frame.\n",
    "    # format: gt object ids, t object ids, distance\n",
    "    acc.update(gt_dets[:,0].astype('int').tolist(), \\\n",
    "              t_dets[:,0].astype('int').tolist(), C)\n",
    "\n",
    "  mh = mm.metrics.create()\n",
    "\n",
    "  summary = mh.compute(acc, metrics=['num_frames', 'idf1', 'idp', 'idr', \\\n",
    "                                     'recall', 'precision', 'num_objects', \\\n",
    "                                     'mostly_tracked', 'partially_tracked', \\\n",
    "                                     'mostly_lost', 'num_false_positives', \\\n",
    "                                     'num_misses', 'num_switches', \\\n",
    "                                     'num_fragmentations', 'mota', 'motp' \\\n",
    "                                    ], \\\n",
    "                      name='acc')\n",
    "\n",
    "  strsummary = mm.io.render_summary(\n",
    "      summary,\n",
    "      #formatters={'mota' : '{:.2%}'.format},\n",
    "      namemap={'idf1': 'IDF1', 'idp': 'IDP', 'idr': 'IDR', 'recall': 'Rcll', \\\n",
    "               'precision': 'Prcn', 'num_objects': 'GT', \\\n",
    "               'mostly_tracked' : 'MT', 'partially_tracked': 'PT', \\\n",
    "               'mostly_lost' : 'ML', 'num_false_positives': 'FP', \\\n",
    "               'num_misses': 'FN', 'num_switches' : 'IDsw', \\\n",
    "               'num_fragmentations' : 'FM', 'mota': 'MOTA', 'motp' : 'MOTP',  \\\n",
    "              }\n",
    "  )\n",
    "  print(strsummary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     num_frames      IDF1       IDP       IDR      Rcll     Prcn     GT  MT  PT  ML    FP    FN  IDsw   FM      MOTA      MOTP\n",
      "acc        2141  0.526952  0.580971  0.482125  0.609706  0.73471  21594  16  33   7  4754  8428   234  422  0.378716  0.173958\n",
      "     num_frames      IDF1       IDP       IDR      Rcll      Prcn     GT   MT  PT  ML    FP  FN  IDsw  FM      MOTA      MOTP\n",
      "acc        2141  0.618829  0.503627  0.802365  0.994844  0.624442  11248  242   8  14  6730  58    27   9  0.394115  0.094197\n",
      "     num_frames      IDF1      IDP       IDR      Rcll     Prcn     GT   MT  PT   ML    FP    FN  IDsw  FM      MOTA      MOTP\n",
      "acc        2141  0.753288  0.75106  0.755529  0.936791  0.93125  17814  240  70  296  1232  1126   167  94  0.858258  0.124866\n"
     ]
    }
   ],
   "source": [
    "motMetricsEnhancedCalculator('output_annotations.txt', \\\n",
    "                             'output.txt')\n",
    "motMetricsEnhancedCalculator('output_retinanet.txt', \\\n",
    "                             'output.txt')\n",
    "motMetricsEnhancedCalculator('output_faster-rcnn.txt', \\\n",
    "                             'output.txt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using TrackEval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Eval Config:\n",
      "USE_PARALLEL         : False                         \n",
      "NUM_PARALLEL_CORES   : 8                             \n",
      "BREAK_ON_ERROR       : True                          \n",
      "RETURN_ON_ERROR      : False                         \n",
      "LOG_ON_ERROR         : c:\\Users\\hicha\\Desktop\\M6_week3\\mcv-m6-2023-team4\\week3\\TrackEval\\error_log.txt\n",
      "PRINT_RESULTS        : True                          \n",
      "PRINT_ONLY_COMBINED  : False                         \n",
      "PRINT_CONFIG         : True                          \n",
      "TIME_PROGRESS        : True                          \n",
      "DISPLAY_LESS_PROGRESS : False                         \n",
      "OUTPUT_SUMMARY       : True                          \n",
      "OUTPUT_EMPTY_CLASSES : True                          \n",
      "OUTPUT_DETAILED      : True                          \n",
      "PLOT_CURVES          : True                          \n",
      "\n",
      "MotChallenge2DBox Config:\n",
      "PRINT_CONFIG         : True                          \n",
      "GT_FOLDER            : c:\\Users\\hicha\\Desktop\\M6_week3\\mcv-m6-2023-team4\\week3\\TrackEval\\data/gt/mot_challenge/\n",
      "TRACKERS_FOLDER      : c:\\Users\\hicha\\Desktop\\M6_week3\\mcv-m6-2023-team4\\week3\\TrackEval\\data/trackers/mot_challenge/\n",
      "OUTPUT_FOLDER        : None                          \n",
      "TRACKERS_TO_EVAL     : None                          \n",
      "CLASSES_TO_EVAL      : ['pedestrian']                \n",
      "BENCHMARK            : MASK-RCNN                     \n",
      "SPLIT_TO_EVAL        : train                         \n",
      "INPUT_AS_ZIP         : False                         \n",
      "DO_PREPROC           : False                         \n",
      "TRACKER_SUB_FOLDER   : data                          \n",
      "OUTPUT_SUB_FOLDER    :                               \n",
      "TRACKER_DISPLAY_NAMES : None                          \n",
      "SEQMAP_FOLDER        : None                          \n",
      "SEQMAP_FILE          : None                          \n",
      "SEQ_INFO             : None                          \n",
      "GT_LOC_FORMAT        : {gt_folder}/{seq}/gt/gt.txt   \n",
      "SKIP_SPLIT_FOL       : False                         \n",
      "\n",
      "CLEAR Config:\n",
      "METRICS              : ['HOTA', 'CLEAR', 'Identity'] \n",
      "THRESHOLD            : 0.5                           \n",
      "PRINT_CONFIG         : True                          \n",
      "\n",
      "Identity Config:\n",
      "METRICS              : ['HOTA', 'CLEAR', 'Identity'] \n",
      "THRESHOLD            : 0.5                           \n",
      "PRINT_CONFIG         : True                          \n",
      "\n",
      "Evaluating 1 tracker(s) on 1 sequence(s) for 1 class(es) on MotChallenge2DBox dataset using the following metrics: HOTA, CLEAR, Identity, Count\n",
      "\n",
      "\n",
      "Evaluating MPNTrack\n",
      "\n",
      "    MotChallenge2DBox.get_raw_seq_data(MPNTrack, MASK-RCNN-03)             0.4143 sec\n",
      "    MotChallenge2DBox.get_preprocessed_seq_data(pedestrian)                0.3203 sec\n",
      "    HOTA.eval_sequence()                                                   0.7374 sec\n",
      "    CLEAR.eval_sequence()                                                  0.1229 sec\n",
      "    Identity.eval_sequence()                                               0.0759 sec\n",
      "    Count.eval_sequence()                                                  0.0000 sec\n",
      "2 eval_sequence(MASK-RCNN-03, MPNTrack)                                  1.6782 sec\n",
      "\n",
      "All sequences for MPNTrack finished in 1.68 seconds\n",
      "\n",
      "HOTA: MPNTrack-pedestrian          HOTA      DetA      AssA      DetRe     DetPr     AssRe     AssPr     LocA      OWTA      HOTA(0)   LocA(0)   HOTALocA(0)\n",
      "MASK-RCNN-03                       58.224    52.88     68.928    59.966    72.26     70.379    92.892    82.197    62.96     70.734    73.557    52.03     \n",
      "COMBINED                           58.224    52.88     68.928    59.966    72.26     70.379    92.892    82.197    62.96     70.734    73.557    52.03     \n",
      "\n",
      "CLEAR: MPNTrack-pedestrian         MOTA      MOTP      MODA      CLR_Re    CLR_Pr    MTR       PTR       MLR       sMOTA     CLR_TP    CLR_FN    CLR_FP    IDSW      MT        PT        ML        Frag      \n",
      "MASK-RCNN-03                       37.825    82.615    38.965    60.975    73.477    28.571    58.929    12.5      27.225    13167     8427      4753      246       16        33        7         421       \n",
      "COMBINED                           37.825    82.615    38.965    60.975    73.477    28.571    58.929    12.5      27.225    13167     8427      4753      246       16        33        7         421       \n",
      "\n",
      "Identity: MPNTrack-pedestrian      IDF1      IDR       IDP       IDTP      IDFN      IDFP      \n",
      "MASK-RCNN-03                       52.695    48.212    58.097    10411     11183     7509      \n",
      "COMBINED                           52.695    48.212    58.097    10411     11183     7509      \n",
      "\n",
      "Count: MPNTrack-pedestrian         Dets      GT_Dets   IDs       GT_IDs    \n",
      "MASK-RCNN-03                       17920     21594     804       56        \n",
      "COMBINED                           17920     21594     804       56        \n",
      "\n",
      "Timing analysis:\n",
      "MotChallenge2DBox.get_raw_seq_data                                     1.1605 sec\n",
      "MotChallenge2DBox.get_preprocessed_seq_data                            0.6487 sec\n",
      "HOTA.eval_sequence                                                     1.4891 sec\n",
      "CLEAR.eval_sequence                                                    0.2432 sec\n",
      "Identity.eval_sequence                                                 0.1548 sec\n",
      "Count.eval_sequence                                                    0.0000 sec\n",
      "eval_sequence                                                          3.7135 sec\n",
      "Evaluator.evaluate                                                     4.3516 sec\n",
      "\n",
      "Eval Config:\n",
      "USE_PARALLEL         : False                         \n",
      "NUM_PARALLEL_CORES   : 8                             \n",
      "BREAK_ON_ERROR       : True                          \n",
      "RETURN_ON_ERROR      : False                         \n",
      "LOG_ON_ERROR         : c:\\Users\\hicha\\Desktop\\M6_week3\\mcv-m6-2023-team4\\week3\\TrackEval\\error_log.txt\n",
      "PRINT_RESULTS        : True                          \n",
      "PRINT_ONLY_COMBINED  : False                         \n",
      "PRINT_CONFIG         : True                          \n",
      "TIME_PROGRESS        : True                          \n",
      "DISPLAY_LESS_PROGRESS : False                         \n",
      "OUTPUT_SUMMARY       : True                          \n",
      "OUTPUT_EMPTY_CLASSES : True                          \n",
      "OUTPUT_DETAILED      : True                          \n",
      "PLOT_CURVES          : True                          \n",
      "\n",
      "MotChallenge2DBox Config:\n",
      "PRINT_CONFIG         : True                          \n",
      "GT_FOLDER            : c:\\Users\\hicha\\Desktop\\M6_week3\\mcv-m6-2023-team4\\week3\\TrackEval\\data/gt/mot_challenge/\n",
      "TRACKERS_FOLDER      : c:\\Users\\hicha\\Desktop\\M6_week3\\mcv-m6-2023-team4\\week3\\TrackEval\\data/trackers/mot_challenge/\n",
      "OUTPUT_FOLDER        : None                          \n",
      "TRACKERS_TO_EVAL     : None                          \n",
      "CLASSES_TO_EVAL      : ['pedestrian']                \n",
      "BENCHMARK            : RetinaNet                     \n",
      "SPLIT_TO_EVAL        : train                         \n",
      "INPUT_AS_ZIP         : False                         \n",
      "DO_PREPROC           : False                         \n",
      "TRACKER_SUB_FOLDER   : data                          \n",
      "OUTPUT_SUB_FOLDER    :                               \n",
      "TRACKER_DISPLAY_NAMES : None                          \n",
      "SEQMAP_FOLDER        : None                          \n",
      "SEQMAP_FILE          : None                          \n",
      "SEQ_INFO             : None                          \n",
      "GT_LOC_FORMAT        : {gt_folder}/{seq}/gt/gt.txt   \n",
      "SKIP_SPLIT_FOL       : False                         \n",
      "\n",
      "CLEAR Config:\n",
      "METRICS              : ['HOTA', 'CLEAR', 'Identity'] \n",
      "THRESHOLD            : 0.5                           \n",
      "PRINT_CONFIG         : True                          \n",
      "\n",
      "Identity Config:\n",
      "METRICS              : ['HOTA', 'CLEAR', 'Identity'] \n",
      "THRESHOLD            : 0.5                           \n",
      "PRINT_CONFIG         : True                          \n",
      "\n",
      "Evaluating 1 tracker(s) on 1 sequence(s) for 1 class(es) on MotChallenge2DBox dataset using the following metrics: HOTA, CLEAR, Identity, Count\n",
      "\n",
      "\n",
      "Evaluating MPNTrack\n",
      "\n",
      "    MotChallenge2DBox.get_raw_seq_data(MPNTrack, RetinaNet-03)             0.5025 sec\n",
      "    MotChallenge2DBox.get_preprocessed_seq_data(pedestrian)                0.3184 sec\n",
      "    HOTA.eval_sequence()                                                   0.7137 sec\n",
      "    CLEAR.eval_sequence()                                                  0.1141 sec\n",
      "    Identity.eval_sequence()                                               0.0639 sec\n",
      "    Count.eval_sequence()                                                  0.0000 sec\n",
      "3 eval_sequence(RetinaNet-03, MPNTrack)                                  1.7236 sec\n",
      "\n",
      "All sequences for MPNTrack finished in 1.72 seconds\n",
      "\n",
      "HOTA: MPNTrack-pedestrian          HOTA      DetA      AssA      DetRe     DetPr     AssRe     AssPr     LocA      OWTA      HOTA(0)   LocA(0)   HOTALocA(0)\n",
      "RetinaNet-03                       51.557    44.528    60.621    45.819    87.963    61.361    93.723    88.35     52.455    56.425    86.343    48.719    \n",
      "COMBINED                           51.557    44.528    60.621    45.819    87.963    61.361    93.723    88.35     52.455    56.425    86.343    48.719    \n",
      "\n",
      "CLEAR: MPNTrack-pedestrian         MOTA      MOTP      MODA      CLR_Re    CLR_Pr    MTR       PTR       MLR       sMOTA     CLR_TP    CLR_FN    CLR_FP    IDSW      MT        PT        ML        Frag      \n",
      "RetinaNet-03                       50.204    86.7      51.07     51.579    99.022    19.643    57.143    23.214    43.344    11138     10456     110       187       11        32        13        176       \n",
      "COMBINED                           50.204    86.7      51.07     51.579    99.022    19.643    57.143    23.214    43.344    11138     10456     110       187       11        32        13        176       \n",
      "\n",
      "Identity: MPNTrack-pedestrian      IDF1      IDR       IDP       IDTP      IDFN      IDFP      \n",
      "RetinaNet-03                       48.736    37.061    71.15     8003      13591     3245      \n",
      "COMBINED                           48.736    37.061    71.15     8003      13591     3245      \n",
      "\n",
      "Count: MPNTrack-pedestrian         Dets      GT_Dets   IDs       GT_IDs    \n",
      "RetinaNet-03                       11248     21594     264       56        \n",
      "COMBINED                           11248     21594     264       56        \n",
      "\n",
      "Timing analysis:\n",
      "MotChallenge2DBox.get_raw_seq_data                                     1.6630 sec\n",
      "MotChallenge2DBox.get_preprocessed_seq_data                            0.9671 sec\n",
      "HOTA.eval_sequence                                                     2.2028 sec\n",
      "CLEAR.eval_sequence                                                    0.3573 sec\n",
      "Identity.eval_sequence                                                 0.2187 sec\n",
      "Count.eval_sequence                                                    0.0000 sec\n",
      "eval_sequence                                                          5.4370 sec\n",
      "Evaluator.evaluate                                                     6.3072 sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run TrackEval/scripts/run_mot_challenge.py --BENCHMARK MASK-RCNN --DO_PREPROC False\n",
    "%run TrackEval/scripts/run_mot_challenge.py --BENCHMARK RetinaNet --DO_PREPROC False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "week2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
