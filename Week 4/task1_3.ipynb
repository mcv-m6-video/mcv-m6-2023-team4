{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.3: Object Tracking with Optical Flow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "import motmetrics\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "from PIL import Image\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to compute IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iou(bboxA, bboxB):\n",
    "    # Code provided by teacher in M1 subject\n",
    "    # compute the intersection over union of two bboxes\n",
    "    \n",
    "    # Format of the bboxes is [xtl, ytl, xbr, ybr, ...], where tl and br\n",
    "    # indicate top-left and bottom-right corners of the bbox respectively.\n",
    "\n",
    "    # determine the coordinates of the intersection rectangle\n",
    "    xA = max(bboxA[0], bboxB[0])\n",
    "    \n",
    "    yA = max(bboxA[1], bboxB[1])\n",
    "    xB = min(bboxA[2], bboxB[2])\n",
    "    yB = min(bboxA[3], bboxB[3])\n",
    "    \n",
    "    # compute the area of intersection rectangle\n",
    "    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    " \n",
    "    # compute the area of both bboxes\n",
    "    bboxAArea = (bboxA[3] - bboxA[1] + 1) * (bboxA[2] - bboxA[0] + 1)\n",
    "    bboxBArea = (bboxB[3] - bboxB[1] + 1) * (bboxB[2] - bboxB[0] + 1)\n",
    "    \n",
    "    iou = interArea / float(bboxAArea + bboxBArea - interArea)\n",
    "    \n",
    "    # return the intersection over union value\n",
    "    return iou\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "def parse_xml(file_path):\n",
    "    \"\"\"\n",
    "    Parses an XML file and extracts bounding box information for each frame and track.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the XML file.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing two dictionaries, `tracks` and `frames`.\n",
    "            `tracks` contains information for each track, with the track IDs as keys and the box information\n",
    "            for each frame as values.\n",
    "            `frames` contains information for each frame, with the frame numbers as keys and a list of boxes as\n",
    "            values.\n",
    "    \"\"\"\n",
    "    # Parse the XML file\n",
    "    tree = ET.parse(file_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    frames = {}\n",
    "\n",
    "    # Iterate over the tracks and extract their bounding box information\n",
    "    for track in root.findall(\".//track[@label='car']\"):\n",
    "        track_id = track.get('id')\n",
    "        for box in track.findall(\".//box\"):\n",
    "            box_frame = int(box.get('frame'))\n",
    "            xtl, ytl, xbr, ybr = map(float, [box.get('xtl'), box.get('ytl'), box.get('xbr'), box.get('ybr')])\n",
    "            outside, occluded, keyframe = map(int, [box.get('outside'), box.get('occluded'), box.get('keyframe')])\n",
    "            parked = box.find(\".//attribute[@name='parked']\").text == 'true'\n",
    "\n",
    "            # Add the box to the list of boxes for this frame\n",
    "            if box_frame not in frames:\n",
    "                frames[box_frame] = []\n",
    "\n",
    "            frames[box_frame].append({\n",
    "                'xtl': xtl,\n",
    "                'ytl': ytl,\n",
    "                'xbr': xbr,\n",
    "                'ybr': ybr,\n",
    "                'track_id': track_id,\n",
    "                'occluded': occluded\n",
    "            })\n",
    "\n",
    "    return frames\n",
    "\n",
    "\n",
    "frames_gt = parse_xml('annotations.xml')\n",
    "frames_gt = dict(sorted(frames_gt.items(), key=lambda x: x[0]))\n",
    "# Open the output file for writing\n",
    "output_file = \"output_annotations.txt\"\n",
    "output_fp = open(output_file, \"w\")\n",
    "\n",
    "for frame in frames_gt:\n",
    "    for bbox in frames_gt[frame]:\n",
    "        x, y, z = -1, -1, -1  # No information about x, y, z\n",
    "        line = \"{},{},{},{},{},{},{},{},{},{}\\n\".format(\n",
    "            str(int(frame)+1),\n",
    "            bbox['track_id'],\n",
    "            bbox['xtl'],\n",
    "            bbox['ytl'],\n",
    "            bbox['xbr'] - bbox['xtl'],\n",
    "            bbox['ybr'] - bbox['ytl'],\n",
    "            1,\n",
    "            x,\n",
    "            y,\n",
    "            z\n",
    "        )\n",
    "\n",
    "        output_fp.write(line)\n",
    "\n",
    "#Release the output file\n",
    "output_fp.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for detecting objects using Detectron2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_objects(predictor, frame):\n",
    "    # Detect objects in the current frame using the pretrained model\n",
    "    outputs = predictor(frame) \n",
    "    current_objects = outputs['instances']\n",
    "\n",
    "    instances = outputs[\"instances\"].to(\"cpu\")\n",
    "    boxes = instances.pred_boxes.tensor.numpy()\n",
    "    #print(\"Boxes\", boxes)\n",
    "    classes = instances.pred_classes.numpy()\n",
    "    #print(\"Classes\", classes)\n",
    "    #print(classes)\n",
    "    scores = instances.scores.numpy()\n",
    "    num_boxes = boxes.shape[0]\n",
    "\n",
    "    return boxes, classes, scores, num_boxes\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for writing tracker output in MOT16 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_tracker_output_MOT16(object_tracker, output_fp):\n",
    "      # Write the tracker output to the output file in the MOT16 format\n",
    "    \n",
    "    for track, bbox in object_tracker.items():\n",
    "    \n",
    "        x, y, z = -1, -1, -1  # No information about x, y, z\n",
    "        line = \"{},{},{},{},{},{},{},{},{},{}\\n\".format(\n",
    "            frame_num,\n",
    "            track,\n",
    "            bbox[0],\n",
    "            bbox[1],\n",
    "            bbox[2] - bbox[0],\n",
    "            bbox[3] - bbox[1],\n",
    "            1,\n",
    "            x,\n",
    "            y,\n",
    "            z\n",
    "        )\n",
    "        output_fp.write(line)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for visualizing result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_tracked_objects_in_frame(frame, object_tracker, prev_object_tracker):\n",
    "    # Visualize the tracked objects in the current frame\n",
    "    v = Visualizer(frame[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
    "    #out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    index_color = 0\n",
    "    for object_id, object_box in object_tracker.items():\n",
    "        out = v.draw_text(f\"{object_id}\", (object_box[0], object_box[1]), font_size=8)\n",
    "        out = v.draw_box(object_box, edge_color='g')\n",
    "    for object_id, object_box in prev_object_tracker.items():\n",
    "        out = v.draw_text(f\"{object_id}\", (object_box[0], object_box[1]), font_size=8)\n",
    "        out = v.draw_box(object_box, alpha=0.2, edge_color='b')\n",
    "\n",
    "    result = out.get_image()[:, :, ::-1]\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for computing Lucas-Kanade optical flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_optical_flow_lucas_kanade(prev_frame, frame, object_box):\n",
    "    #Define the parameters for Lucas-Kanade optical flow\n",
    "    lk_params = dict(winSize=(15, 15), maxLevel=4, criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "    #Define the feature points to track (Shi Tomasi corner detection)\n",
    "    feature_params = dict(maxCorners=100, qualityLevel=0.3, minDistance=7, blockSize=7)\n",
    "    #Covnert prev_frame and frame to gray\n",
    "    prev_frame_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "    #pick bounding box\n",
    "    p0 = cv2.goodFeaturesToTrack(prev_frame_gray[int(object_box[1]):int(object_box[3]), int(object_box[0]):int(object_box[2])], mask=None, **feature_params)\n",
    "\n",
    "    if p0 is None:\n",
    "        #Computing the OF for all the pixels inside detection if we do not have good points.\n",
    "        height = int(object_box[3]) - int(object_box[1])\n",
    "        width = int(object_box[2]) - int(object_box[0])\n",
    "        p0 = np.array([[x, y] for y in range(int(object_box[1]), int(object_box[3])) for x in\n",
    "                    range(int(object_box[0]), int(object_box[2]))],\n",
    "                    dtype=np.float32).reshape((-1, 1, 2))\n",
    "    #Calculate the optical flow \n",
    "    p1, st, err = cv2.calcOpticalFlowPyrLK(prev_frame, frame, p0, None, **lk_params)\n",
    "\n",
    "\n",
    "    #print(p1)\n",
    "    #print(p1.shape)\n",
    "\n",
    "    flow = p1 - p0\n",
    "    flow[st == 0] = 0\n",
    "    flow[:,:,1] = - flow[:,:,1]\n",
    "    flow = np.mean(flow, axis=(0,1))\n",
    "    print(flow)\n",
    "    return flow\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for computing Pyflow optical flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_optical_flow_pyflow(prev_frame, frame, object_box):\n",
    "    im1 = prev_frame.astype(float) / 255.\n",
    "    im2 = frame.astype(float) / 255.\n",
    "\n",
    "\n",
    "    # Flow Options:\n",
    "    alpha = 0.012\n",
    "    ratio = 0.75\n",
    "    minWidth = 20\n",
    "    nOuterFPIterations = 7\n",
    "    nInnerFPIterations = 1\n",
    "    nSORIterations = 30\n",
    "    colType = 0  # 0 or default:RGB, 1:GRAY (but pass gray image with shape (h,w,1))\n",
    "\n",
    "    s = time.time()\n",
    "    bounding_box_im1 = im1[int(object_box[1]):int(object_box[3]), int(object_box[0]):int(object_box[2])].copy(order='C')\n",
    "    bounding_box_im2 = im2[int(object_box[1]):int(object_box[3]), int(object_box[0]):int(object_box[2])].copy(order='C')\n",
    "    u, v, im2W = pyflow.coarse2fine_flow(\n",
    "        bounding_box_im1, bounding_box_im2, alpha, ratio, minWidth, nOuterFPIterations, nInnerFPIterations,\n",
    "        nSORIterations, colType)\n",
    "    e = time.time()\n",
    "    print('Time Taken: %.2f seconds for image of size (%d, %d, %d)' % (\n",
    "        e - s, bounding_box_im1.shape[0], bounding_box_im1.shape[1], bounding_box_im1.shape[2]))\n",
    "    flow = np.concatenate((u[..., None], v[..., None]), axis=2)\n",
    "    flow = np.mean(flow, axis=(0,1))\n",
    "\n",
    "    return flow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object tracking from previous week using optical flow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store detections in a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the video\n",
    "video = cv2.VideoCapture('vdo.avi')\n",
    "\n",
    "\n",
    "#Load configuration\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\"))\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model\n",
    "# Find a model from detectron2's model zoo. You can use the https://dl.fbaipublicfiles... url as well\n",
    "cfg.MODEL.WEIGHTS = 'model_final.pth'\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "frames = {}\n",
    "frame_num = 1\n",
    "while True:\n",
    "    \n",
    "    # Read the current frame from the video\n",
    "    ret, frame = video.read()\n",
    "\n",
    "    # Stop if there are no more frames\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    boxes, classes, scores, num_boxes = detect_objects(predictor, frame)    \n",
    "    frames[frame_num] = {}\n",
    "    frames[frame_num]['boxes'] = boxes\n",
    "    frames[frame_num]['classes'] = classes\n",
    "    frames[frame_num]['scores'] = scores\n",
    "    frames[frame_num]['num_boxes'] = num_boxes\n",
    "    frame_num += 1\n",
    "\n",
    "# save dictionary to person_data.pkl file\n",
    "with open('detections.pkl', 'wb') as fp:\n",
    "    pickle.dump(frames, fp)\n",
    "    print('dictionary saved successfully to file')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the video\n",
    "video = cv2.VideoCapture('vdo.avi')\n",
    "import pickle\n",
    "\n",
    "# #Load configuration\n",
    "# cfg = get_cfg()\n",
    "# cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\"))\n",
    "# cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
    "# cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model\n",
    "# # Find a model from detectron2's model zoo. You can use the https://dl.fbaipublicfiles... url as well\n",
    "# cfg.MODEL.WEIGHTS = 'model_final.pth'\n",
    "# predictor = DefaultPredictor(cfg)\n",
    "\n",
    "# Read dictionary pkl file\n",
    "with open('detections.pkl', 'rb') as fp:\n",
    "    frames = pickle.load(fp)\n",
    "\n",
    "\n",
    "# Initialize variables\n",
    "\n",
    "object_tracker = {}\n",
    "optical_flow = {}\n",
    "current_id = 0\n",
    "frame_num = 1\n",
    "prev_frame = None\n",
    "\n",
    "# Open the output file for writing\n",
    "output_file = \"pyflow.txt\"\n",
    "output_fp = open(output_file, \"w\")\n",
    "while True:\n",
    "    \n",
    "    # Read the current frame from the video\n",
    "    ret, frame = video.read()\n",
    "    print(frame_num)\n",
    "\n",
    "    # Stop if there are no more frames\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Initialize a new dictionary to store the detected objects in the current frame\n",
    "    new_object_tracker = {}\n",
    "    prev_object_tracker = object_tracker.copy()\n",
    "    #boxes, classes, scores, num_boxes = detect_objects(predictor, frame)\n",
    "    boxes = frames[frame_num]['boxes']\n",
    "    classes = frames[frame_num]['classes']\n",
    "    scores = frames[frame_num]['scores']\n",
    "    num_boxes = frames[frame_num]['num_boxes']\n",
    "\n",
    "    for i in range(num_boxes):\n",
    "        box = boxes[i]\n",
    "        score = scores[i]\n",
    "        class_object = classes[i]\n",
    "        # Filter out low-scoring objects\n",
    "        if score < 0.7:\n",
    "            continue\n",
    "\n",
    "        \n",
    "\n",
    "        # Try to match the detected object with a previously tracked object based on IoU\n",
    "        best_match_id = None\n",
    "        best_match_iou = 0\n",
    "        for object_id, object_box in object_tracker.items():\n",
    "            if prev_frame.all() != None:\n",
    "                #optical_flow = compute_optical_flow_pyflow(prev_frame, frame, object_box)\n",
    "                optical_flow = compute_optical_flow_lucas_kanade(prev_frame, frame, object_box) #too slow\n",
    "                print(optical_flow)\n",
    "                object_box[0] = object_box[0] + optical_flow[0] if object_box[0] + optical_flow[0] >= 0 else object_box[0] # xtl + optical_flow x\n",
    "                object_box[1] = object_box[1] + optical_flow[1] if object_box[1] + optical_flow[1] >= 0 else object_box[1]# ytl + optical_flow y\n",
    "                object_box[2] = object_box[2] + optical_flow[0] if object_box[2] + optical_flow[0] >= 0 else object_box[2]# xbr + optical_flow x\n",
    "                object_box[3] = object_box[3] + optical_flow[1] if object_box[3] + optical_flow[1] >= 0 else object_box[3]# ybr + optical_flow y\n",
    "                prev_object_tracker[object_id] = object_box\n",
    "            iou = compute_iou(box, object_box)\n",
    "            if iou > best_match_iou:\n",
    "                best_match_iou = iou\n",
    "                best_match_id = object_id\n",
    "        # If the best match has IoU > 0.4, assign the same ID to the detected object\n",
    "        print(best_match_iou)\n",
    "        if best_match_id is not None and best_match_iou > 0.3:\n",
    "            new_object_tracker[best_match_id] = box\n",
    "            del object_tracker[best_match_id]\n",
    "        else:\n",
    "            # Assign a new ID to each new detected object\n",
    "            current_id += 1\n",
    "            new_object_tracker[current_id] = box\n",
    "      \n",
    "    # Update the object tracker for the current frame\n",
    "    object_tracker = new_object_tracker\n",
    "    \n",
    "    result = visualize_tracked_objects_in_frame(frame, object_tracker, prev_object_tracker)\n",
    "    # Display the current frame with the tracked objects\n",
    "    cv2.imwrite('frames/frame_{}.png'.format(frame_num), result)\n",
    "    cv2.imshow(\"Object tracking\", result)\n",
    "    \n",
    "    if cv2.waitKey(50) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "    write_tracker_output_MOT16(object_tracker, output_fp)\n",
    "    prev_frame = frame\n",
    "    frame_num += 1\n",
    "\n",
    "# Release the video and the output file and close all windows\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n",
    "output_fp.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motmetrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def motMetricsEnhancedCalculator(gtSource, tSource):\n",
    "  # import required packages\n",
    "  import motmetrics as mm\n",
    "  import numpy as np\n",
    "  \n",
    "  # load ground truth\n",
    "  gt = np.loadtxt(gtSource, delimiter=',')\n",
    "\n",
    "  # load tracking output\n",
    "  t = np.loadtxt(tSource, delimiter=',')\n",
    "\n",
    "  # Create an accumulator that will be updated during each frame\n",
    "  acc = mm.MOTAccumulator(auto_id=True)\n",
    "\n",
    "  # Max frame number maybe different for gt and t files\n",
    "  for frame in range(int(gt[:,0].max())):\n",
    "    frame += 1 # detection and frame numbers begin at 1\n",
    "\n",
    "    # select id, x, y, width, height for current frame\n",
    "    # required format for distance calculation is X, Y, Width, Height \\\n",
    "    # We already have this format\n",
    "    gt_dets = gt[gt[:,0]==frame,1:6] # select all detections in gt\n",
    "    t_dets = t[t[:,0]==frame,1:6] # select all detections in t\n",
    "\n",
    "    C = mm.distances.iou_matrix(gt_dets[:,1:], t_dets[:,1:], \\\n",
    "                                max_iou=0.5) # format: gt, t\n",
    "\n",
    "    # Call update once for per frame.\n",
    "    # format: gt object ids, t object ids, distance\n",
    "    acc.update(gt_dets[:,0].astype('int').tolist(), \\\n",
    "              t_dets[:,0].astype('int').tolist(), C)\n",
    "\n",
    "  mh = mm.metrics.create()\n",
    "\n",
    "  summary = mh.compute(acc, metrics=['num_frames', 'idf1', 'idp', 'idr', \\\n",
    "                                     'recall', 'precision', 'num_objects', \\\n",
    "                                     'mostly_tracked', 'partially_tracked', \\\n",
    "                                     'mostly_lost', 'num_false_positives', \\\n",
    "                                     'num_misses', 'num_switches', \\\n",
    "                                     'num_fragmentations', 'mota', 'motp' \\\n",
    "                                    ], \\\n",
    "                      name='acc')\n",
    "\n",
    "  strsummary = mm.io.render_summary(\n",
    "      summary,\n",
    "      #formatters={'mota' : '{:.2%}'.format},\n",
    "      namemap={'idf1': 'IDF1', 'idp': 'IDP', 'idr': 'IDR', 'recall': 'Rcll', \\\n",
    "               'precision': 'Prcn', 'num_objects': 'GT', \\\n",
    "               'mostly_tracked' : 'MT', 'partially_tracked': 'PT', \\\n",
    "               'mostly_lost' : 'ML', 'num_false_positives': 'FP', \\\n",
    "               'num_misses': 'FN', 'num_switches' : 'IDsw', \\\n",
    "               'num_fragmentations' : 'FM', 'mota': 'MOTA', 'motp' : 'MOTP',  \\\n",
    "              }\n",
    "  )\n",
    "  print(strsummary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     num_frames      IDF1       IDP       IDR      Rcll      Prcn     GT  MT  PT  ML   FP   FN  IDsw  FM      MOTA      MOTP\n",
      "acc        2141  0.774495  0.781302  0.767806  0.970686  0.987748  21594  53   3   0  260  633    71  52  0.955358  0.052928\n",
      "     num_frames      IDF1       IDP       IDR      Rcll      Prcn     GT  MT  PT  ML   FP   FN  IDsw  FM      MOTA      MOTP\n",
      "acc        2141  0.769377  0.771563  0.767204  0.973326  0.978856  21594  53   3   0  454  576    96  51  0.947856  0.053546\n"
     ]
    }
   ],
   "source": [
    "motMetricsEnhancedCalculator('gt.txt', \\\n",
    "                             'pyflow.txt')\n",
    "motMetricsEnhancedCalculator('gt.txt', \\\n",
    "                             'Faster-RCNN-finetuned-03.txt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = './frames'\n",
    "num_digits = 4\n",
    "\n",
    "# Get a list of files in the directory\n",
    "file_list = os.listdir(directory_path)\n",
    "\n",
    "# Loop through each file in the list\n",
    "for filename in file_list:\n",
    "    # Check if the file starts with \"frame_\" and ends with \".png\"\n",
    "    if filename.startswith('frame_') and filename.endswith('.png'):\n",
    "        # Extract the frame number from the filename\n",
    "        frame_num = int(filename.split('_')[1].split('.')[0])\n",
    "        # Create the new filename with leading zeros\n",
    "        new_filename = f\"frame_{frame_num:0{num_digits}}.png\"\n",
    "        # Rename the file\n",
    "        os.rename(os.path.join(directory_path, filename), os.path.join(directory_path, new_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "# Set up parameters\n",
    "frame_rate = 15.0  # frames per second\n",
    "output_file = 'output.mp4'\n",
    "\n",
    "\n",
    "height, width, _ = cv2.imread('./frames/frame_0001.png').shape\n",
    "size = (width, height)\n",
    "# Get a list of image files\n",
    "image_dir = './frames'\n",
    "image_files = os.listdir(image_dir)\n",
    "#\n",
    "# Sort the image files\n",
    "image_files = sorted(image_files)\n",
    "# Create a cv2.VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "video_writer = cv2.VideoWriter(output_file, fourcc, frame_rate, size)\n",
    "\n",
    "# Iterate over the image files\n",
    "for image_file in image_files:\n",
    "    print(image_file)\n",
    "    image_path = os.path.join(image_dir, image_file)\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "\n",
    "    cv2.imshow(\"Track\", image)\n",
    "    if cv2.waitKey(50) & 0xFF == ord('q'):\n",
    "        break\n",
    "    video_writer.write(image)\n",
    "\n",
    "# Release the cv2.VideoWriter object\n",
    "video_writer.release()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TrackEval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run TrackEval/scripts/run_mot_challenge.py --BENCHMARK lucas-kanade --DO_PREPROC False #median\n",
    "%run TrackEval/scripts/run_mot_challenge.py --BENCHMARK lucas-kanade-mean --DO_PREPROC False #mean"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "week2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
